\linenumbers
%   Filename    : chapter_1.tex 
\chapter{Introduction}
\label{sec:researchdesc}    %labels help you reference sections of your document

\section{Overview}
\label{sec:overview}

A type of propaganda or \textit{yellow journalism}, fake news \cite{nyt-trump-lies} can be categorized as deliberate misinformation spread via print media, broadcast media, or online media. The rampant rise of fake news propagated over the Internet and social media has become a cause for concern.

According to the World Economic Forum \cite{weforum-report}, misinformation ranks among the world's top global risks as fake news outlets see astounding traffic and engagement. An economic analysis by Israel-based cybersecurity firm CHEQ and the University of Baltimore \cite{pids-report} reveals that fake news costs the global economy a baffling 78 billion USD. A survey from Social Weather Stations (SWS) \cite{juan-felix-et-al-2023} reports that 51\% of Filipinos find it difficult to spot fake news. It comes as no surprise that fake news makes its mark on Philippine history in the 2016 presidential elections. Journalists and political analysts speculate that Philippine former President Rodrigo Duterte's landslide victory in 2016 has been largely brought about by paid trolls disseminating articles of fake news through social media outlets \cite{harvard-cyber-report}. During the 2016 elections, Duterte popularizes a depiction of the Philippines as a \enquote{\textit{narco-state}}\cite{demick2016duterte}. He earns tremendous publicity through his narco-state rhetoric, justifying more than 7,000 extra-judicial killings \cite{alconaba2016digong} and gaining enough notoriety to sway the voters to his corner. Despite Duterte's insistence that his rhetoric is the truth, the United Office on Drugs and Crime claims otherwise — the Philippines' drug use prevalence is lower than the global average \cite{yee2017posttruth}.

A number of institutions have devised various approaches to combat fake news. These approaches can be broadly categorized into four primary areas: the language approach, the knowledge based approach, the machine learning approach, and the hybrid approach \cite{debeer2020approaches}.

In the language approach, a human or software inspects linguistic structure to identify fake news through grammar and syntax \cite{burkhardt2017history}. Authors of fake news often have great control over its contents, but they can be identified through their style of writing \cite{yang2018ti-cnn}. The language approach also entails bag of words, semantic analysis, and deep syntax. The bag of words method assumes independence and importance of each word in a paragraph \cite{burkhardt2017history}. Analysis of word frequencies (also called n-grams) is carried out to identify misinformation \cite{thota2018fake}. However, the bag of words method does not take context into consideration so its practicality is limited \cite{potthast2017stylometric}. Semantic analysis involves the determination of truthfulness through personal experience, based on the premise that honest writers are more likely to make similar remarks about a topic \cite{chen2015news}. Deep syntax exploits probabilistic context free grammars to transform sentences into a set of rules used in analyzing a piece of text, which may lead to patterns that ultimately discern between truth and lies \cite{zhou2018fake, Stahl2018FakeND}.

The knowledge based approach requires a myriad of fact-checking techniques to identify fake new. However, this approach is challenged by fake news spreading swiftly and unchecked through social media platforms \cite{qazvinian2011rumor}, which necessitates some form of automation in detecting fake news. Knowledge based approaches can be further categorized into expert oriented fact checking, computational oriented fact checking, and crowd sourcing \cite{debeer2020approaches}. Expert oriented fact checking employs professionals in verifying the accuracy of a particular claim through manual research, comparing text to another which has been previously fact checked \cite{vlachos2014factchecking}.  The computational based approach leverages automated fact checking tools in determining the authenticity of news \cite{ahmed2019combining}. A tool named ClaimBuster \cite{claimbuster, hassan2017proposal} has been developed to automate the identification of English language fake news through machine learning and natural language processing \cite{hassan2017toward}. It requires a database of known facts to compare context with social media posts, interviews, and speeches in real time, delivering results to the user \cite{hassan2017toward}. Crowd-sourcing approach, on the other hand, relies on the wisdom of the crowd in determining the authenticity of a claim \cite{ahmed2019combining}. The accuracy of news is measured through a collective decision of the crowd \cite{pennycook2019fighting}. An example of a platform that enables the crowdsourcing approach is Facebook \cite{tschiatschek2017detecting}. In 2017, the National Union of Journalists in the Philippines (NUJP) releases Fakeblok, a Chrome web extension that blocks articles by known fake news sites from appearing on a user's Facebook feed \cite{inquirer-fakeblok, rappler-fakeblok}. Fakeblok blocks news articles from websites known to publish fake news. These websites tagged as fake news publishers are collected in a database maintained by the NUJP. A website may be reported by users as fraudulent. Once reported, a team of expert Filipino journalists scrutinizes the website. If found fraudulent, it is added to the database \cite{cdi-fakeblok}. However, as of the time of writing, the Fakeblok extension can no longer be found on the Chrome web store, rendering it unavailable to the public.

In the machine learning approach, datasets are used to train models in identifying fake news \cite{debeer2020approaches}. Machine learning models may be used to automate fake news detection. Datasets may be constructed through crowdsourcing \cite{perezrosas2018automatic} or webscraping \cite{cruz2020localization}. Twitter implements a machine learning powered approach called the rumor identification framework, where the metadata of tweets is processed to alert users if a tweet may be false \cite{sivasangari2018modern}. The Twitter crawler has also been developed by Twitter, a machine learning powered system that collates tweets into a database, making comparisons feasible \cite{atodiresei2018identifying}. Recent studies advocate for the hybrid approach \cite{debeer2020approaches}, integrating human knowledge engineering with the machine learning approach in identifying fake news \cite{ruchansky2017csi, okoro2018hybrid}. However, this paper turns its lens exclusively on the machine learning approach in tackling the identification of Filipino language fake news. We treat the classification of fake news as a computer science problem.

\section{Problem Statement}

In the past decade, machine learning (ML) models have made
great strides in distinguishing between fake and authentic news articles \cite{ahmed2021detecting}. Fake news via false or sensational claims are being identified by Facebook, Twitter, and Instagram through ML models \cite{debeer2020approaches}. ML models enable a system to intelligently analyze patterns from data, with no specific programming. They can be grouped into four major categories: supervised, unsupervised, semi-supervised, and reinforcement \cite{sarker2021machine}.

Deep learning (DL) models, on the other hand, are a subset of ML models that utilize a computational architecture (neural network) comprised of multiple input, output, and hidden layers to process data \cite{sarker2021machine}. The performance between the two types of model varies, with DL generally performing better on large datasets \cite{xin2018machine, sarker2020cybersecurity}.

A study by \citeA{khan-2021} benchmarks multiple ML and DL models in classifying English language fake news. They use a dataset containing English language news articles written about a vast array of topics ranging from politics, sports, and entertainment. Their results suggest that detecting English language fake news using ML models yields favorable outcomes, with Naïve Bayes achieving a 93\% accuracy on their joint corpus. However, their study utilizes a relatively large dataset containing 80,000 news articles written in English. Unfortunately, as of the time of writing, no such dataset exists for news articles in the Filipino language.

To begin filling this gap, \citeA{cruz2020localization} pioneer the first low-resource Filipino language news dataset with 3,206 expertly labeled articles. They benchmark various machine learning techniques to train robust fake news classifiers from a relatively small amount of data. Despite their promising results, the models that they investigate cannot be easily deployed for consumer-level applications, thus having a limited audience. The deployment of Bidirectional Encoder Representations from Transformers (BERT), a state-of-the-art DL model used in Cruz's study, costs anywhere from 50,000 USD to 1,600,000 USD \cite{paleyes-2022} depending on the size of the model. This cost of deployment is unreasonable for institutions and companies. Therefore, we will investigate lightweight ML models for deployment that may provide adequate performance in distinguishing between fake and authentic Filipino language news articles.

\section{Research Objectives}
\label{sec:researchobjectives}

\subsection{General Objective}
\label{sec:generalobjective}

We will investigate ML techniques that may provide adequate performance in distinguishing between fake and authentic Filipino language news articles. To this end, we will build a dataset of Filipino language news articles to augment Fake News Filipino \cite{fake-news-filipino}. In training the models, we will extract Filipino linguistic features \cite{imperial-2020, imperial-2021} through natural language processing. Our study will culminate into the deployment of the most suitable ML model as a cross-browser extension for detecting fake news.

\subsection{Specific Objectives}
\label{sec:specificobjectives}

\begin{enumerate}
   \item To source Filipino language news articles from the web and build a balanced dataset of fake and authentic news articles;
   \item To extract Filipino linguistic features from a corpus of multi-domain Filipino language news articles;
   \item  To train machine learning models in classifying fake Filipino language news articles through Filipino linguistic features;
   \item To determine the combinations of Filipino linguistic features that yield the most accurate models; and
   \item To deploy the most suitable model as a web service and minimize cost of deployment;
\end{enumerate}

\section{Scope and Limitations of the Research}
\label{sec:scopelimitations}

In this study, we will investigate machine learning models, excluding pre-trained and deep learning models. We limit our study to news articles and exclude other forms of fake news such as spam and tweets. We constrain the machine learning techniques that we will use in the study to a low-resource dataset, Fake News Filipino \cite{fake-news-filipino}, augmented by a similar dataset of our own. Adhering to the dataset construction methodology presented by \citeA{cruz2020localization}, we will source Filipino language news articles from the web via scraping. Authentic news will be sourced from mainstream Filipino language news websites like The Philippine Star and ABS-CBN. Fake news will be sourced from fraudulent online sites tagged by non-profit independent fact-checking organizations such as Verafiles and the NUJP. To identify the model(s) that exhibit the best performance, we will use accuracy and model size as primary metrics for ranking. The most suitable model will be deployed in an application system. The application system will be constrained to a user-script on the client-side and a web service running on a cloud server. We will utilize Tampermonkey (a cross-browser extension manager) and Render (a platform as a service vendor with a free-forever tier) in deploying the application system to minimize cost of deployment.

\section{Significance of the Research}
\label{sec:significance}

Our study is significant to the field of machine learning and fake news detection due to the following reasons.

Building on the work of \citeA{cruz2020localization}, our study contributes to the field of machine learning and computer science by investigating possible machine learning models that can distinguish between fake and authentic Filipino language news articles. We offer a more extensive and diverse collection of news articles by building a dataset similar to Fake News Filipino \cite{fake-news-filipino}. Our approach not only enhances the robustness of potential models in this study, but also provides a more comprehensive dataset that may be utilized in future research.

Furthermore, we conduct our study with the eventual goal of deploying a lightweight application system for the Filipino audience to aid them in fact-checking and avoiding harm caused by misinformation and disinformation. We pave the way for the low-cost deployment of machine learning models for fake news detection to the benefit of various institutions, particularly those engaged in tagging fake news websites. The exploration of low-cost ML deployment strategies will be beneficial for computer scientists aiming to implement ML models in resource-constrained contexts. Our insights could further the development of cost-effective solutions when deploying fake news detection ML models in various settings.

For policymakers, our study provides them with leverage in informing and shaping policies congruent to information integrity. The low-cost deployment of effective fake news detection models may be integrated into broader strategies aimed at preventing the spread of misinformation and maintaining a trustworthy Filipino news network. The deployment of a lightweight application system for fake news detection may serve as a practical tool for policymakers to empower the public in distinguishing between authentic and fake news. We dedicate our efforts in this study to promoting media literacy and arming individuals with an accessible fact-checking tool to combat fake news effectively.