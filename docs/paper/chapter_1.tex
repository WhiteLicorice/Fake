%\linenumbers
%   Filename    : chapter_1.tex
\chapter{Introduction}
\label{sec:researchdesc}    %labels help you reference sections of your document

\section{Overview}
\label{sec:overview}

A type of propaganda or \textit{yellow journalism}, fake news \cite{nyt-trump-lies} can be categorized as deliberate misinformation spread via print media, broadcast media, or online media. The rampant rise of fake news propagated over the internet and social media has become a cause for concern.

According to the World Economic Forum \cite{weforum-report}, misinformation ranks among the world's top global risks as fake news outlets see astounding traffic and engagement. An economic analysis by Israel-based cybersecurity firm CHEQ and the University of Baltimore \cite{pids-report} reveals that fake news costs the global economy a baffling 78 billion USD. A survey from Social Weather Stations (SWS) \cite{juan-felix-et-al-2023} reports that 51\% of Filipinos find it difficult to spot fake news. Journalists and political analysts speculate that Philippine former President Rodrigo Duterte's landslide victory in the 2016 presidential elections has been largely brought about by paid trolls disseminating fake news articles through social media outlets \cite{harvard-cyber-report}. During the 2016 elections, Duterte popularizes a depiction of the Philippines as a \enquote{\textit{narco-state}}\cite{demick2016duterte}. He earns tremendous publicity through his narco-state rhetoric, justifying more than 7,000 extra-judicial killings \cite{alconaba2016digong} and gaining enough notoriety to sway the voters to his corner. Despite Duterte's insistence that his rhetoric is the truth, the United Office on Drugs and Crime claims otherwise — the Philippines' drug use prevalence is lower than the global average \cite{yee2017posttruth}.

A number of institutions have devised several strategies to combat fake news. These strategies can be broadly categorized into four primary areas: the language approach, the knowledge-based approach, the machine learning approach, and the hybrid approach \cite{debeer2020approaches}.

In the language approach, a human or software inspects linguistic structure to identify fake news through grammar and syntax \cite{burkhardt2017history}. Authors of fake news often have great control over its contents, but they can be identified through their style of writing \cite{yang2018ti-cnn}. The language approach also entails bag of words, semantic analysis, and deep syntax. The bag of words method assumes independence and importance of each word in a paragraph \cite{burkhardt2017history}. Analysis of word frequencies (also called n-grams) is carried out to identify misinformation \cite{thota2018fake}. However, the bag of words method does not take context into consideration, so its practicality is limited \cite{potthast2017stylometric}. Semantic analysis involves the determination of truthfulness through the comparison of personal experience to a profile derived from related articles, based on the premise that honest writers are more likely to make similar remarks about a topic \cite{chen2015news}. Deep syntax exploits probabilistic context free grammars to transform sentences into a set of rules used in analyzing a piece of text, which may lead to patterns that ultimately discern between truth and lies \cite{zhou2018fake, Stahl2018FakeND}.

The knowledge-based approach requires a myriad of fact-checking techniques to identify fake new. However, this approach is challenged by fake news spreading swiftly and unchecked through social media platforms \cite{qazvinian2011rumor}, which necessitates some form of automation in detecting fake news. Knowledge-based approaches can be further categorized into expert oriented fact checking, computational oriented fact checking, and crowdsourcing \cite{debeer2020approaches}. Expert oriented fact checking employs professionals in verifying the accuracy of a particular claim through manual research, comparing text to another which has been previously fact-checked \cite{vlachos2014factchecking}. The computational based approach leverages automated fact checking tools in determining the authenticity of news \cite{ahmed2019combining}. A tool named ClaimBuster \cite{claimbuster, hassan2017proposal} has been developed to automate the identification of English language fake news through machine learning and natural language processing \cite{hassan2017toward}. It requires a database of known facts to compare context with social media posts, interviews, and speeches in real time, delivering results to the user \cite{hassan2017toward}. Crowdsourcing approach, on the other hand, relies on the wisdom of the crowd in determining the authenticity of a claim \cite{ahmed2019combining}. The accuracy of news is measured through the collective decision of the crowd \cite{pennycook2019fighting}. An example of a platform that enables the crowdsourcing approach is Facebook \cite{tschiatschek2017detecting}. In 2017, the National Union of Journalists in the Philippines (NUJP) releases Fakeblok, a Chrome web extension that blocks articles by known fake news publishers from appearing on a user's Facebook feed \cite{inquirer-fakeblok, rappler-fakeblok}. These websites tagged as fake news publishers are collected in a database maintained by the NUJP. A website may be reported by users as fraudulent. Once reported, a team of expert Filipino journalists scrutinizes the website. If found fraudulent, it is added to the database \cite{cdi-fakeblok}. However, as of the time of writing, the Fakeblok extension can no longer be found on the Chrome web store, rendering it unavailable to the public.

In the machine learning approach, datasets are used to train models in identifying fake news \cite{debeer2020approaches}. Machine learning models may be used to automate fake news detection. Datasets may be constructed through crowdsourcing \cite{perezrosas2018automatic} or webscraping \cite{cruz2020localization}. Twitter implements a machine learning powered approach called the rumor identification framework, where the metadata of tweets is processed to alert users if a tweet may be false \cite{sivasangari2018modern}. The Twitter crawler has also been developed by Twitter, a machine learning powered system that collates tweets into a database, making comparisons feasible \cite{atodiresei2018identifying}. Recent studies advocate for the hybrid approach \cite{debeer2020approaches}, integrating human knowledge engineering with the machine learning approach in identifying fake news \cite{ruchansky2017csi, okoro2018hybrid}. However, this paper turns its lens exclusively on the machine learning approach in tackling the identification of Filipino language fake news. The classification of fake news is treated as a computer science problem.

\section{Problem Statement}

In the past decade, machine learning models have made
great strides in distinguishing between fake and authentic news articles \cite{ahmed2021detecting}. Fake news via false or sensational claims are being identified by Facebook, Twitter, and Instagram through machine learning models \cite{debeer2020approaches}. Machine learning models enable a system to intelligently analyze patterns from data, with no specific programming. They can be grouped into four major categories: supervised, unsupervised, semi-supervised, and reinforcement \cite{sarker2021machine}.

Deep learning models, on the other hand, are a subset of machine learning models that utilize a computational architecture (neural network) comprised of multiple input, output, and hidden layers to process data \cite{sarker2021machine}. The performance between the two types of model varies, with deep learning generally performing better on large datasets \cite{xin2018machine, sarker2020cybersecurity}.

A study by \citeA{khan-2021} benchmarks multiple machine learning and deep learning models in classifying English language fake news. They use a dataset containing English language news articles written about a vast array of topics ranging from politics, sports, and entertainment. Their results suggest that detecting English language fake news using machine learning models yields favorable outcomes, with Naïve Bayes achieving a 93\% accuracy on their joint corpus. However, their study utilizes a relatively large dataset containing 80,000 news articles written in English. Unfortunately, as of the time of writing, no such dataset exists for news articles in the Filipino language.

To begin filling this gap, \citeA{cruz2020localization} pioneer the first low-resource Filipino language news dataset with 3,206 expertly labeled articles. They benchmark various machine learning techniques to train robust fake news classifiers from a relatively small amount of data. Despite their promising results, the models that they investigate cannot be easily deployed for consumer-level applications, thus having a limited audience. The deployment of Bidirectional Encoder Representations from Transformers (BERT), a state-of-the-art deep learning model used in Cruz's study, costs anywhere from 50,000 USD to 1,600,000 USD \cite{paleyes-2022} depending on the size of the model. This cost of deployment is unreasonable for institutions and companies. Therefore, we will investigate lightweight machine learning models that may provide adequate performance in distinguishing between fake and authentic Filipino language news articles.

\section{Research Objectives}
\label{sec:researchobjectives}

\subsection{General Objective}
\label{sec:generalobjective}

We investigate machine learning models that may provide adequate performance in distinguishing between fake and authentic Filipino language news articles. To this end, we construct a dataset of Filipino language news articles, named Fake News Filipino 2024, to augment Fake News Filipino \cite{fake-news-filipino}. We build a third dataset, a joint corpus that combines the two datasets. In training the models, we extract Filipino linguistic features \cite{imperial-2020, imperial-2021} through natural language processing techniques. We perform hyperparameter tuning and benchmark the performance of these classifiers across the three datasets. Lastly, we deploy the most suitable model as a cross-browser web extension for classifying Filipino language fake news articles.

\subsection{Specific Objectives}
\label{sec:specificobjectives}

Specifically, we will:

\begin{enumerate}
   \item Source Filipino language news articles from the web and build a balanced dataset of fake and authentic news articles;
   \item Extract Filipino linguistic features from a corpus of multi-domain Filipino language news articles;
   \item Train machine learning models in classifying fake Filipino language news articles through Filipino linguistic features;
   \item Benchmark machine learning models, performing hyperparameter tuning, across three different datasets; and
   \item Deploy the most suitable model as a web service and minimize cost of deployment;
\end{enumerate}

\section{Scope and Limitations of the Research}
\label{sec:scopelimitations}

In this study, we investigate machine learning models, excluding pre-trained and deep learning models. We limit our study to news articles and exclude other forms of fake news such as spam and tweets. We constrain the machine learning models in the study to a low-resource dataset, Fake News Filipino \cite{fake-news-filipino}, augmented by a similar dataset of our own, Fake News Filipino 2024. Adhering to the dataset construction methodology presented by \citeA{cruz2020localization}, Filipino language news articles are sourced from the internet via webscraping. Authentic news articles are sourced from mainstream Filipino language news websites like The Philippine Star and ABS-CBN. Fake news articles are sourced from fraudulent online sites tagged by non-profit independent fact-checking organizations such as Verafiles and the NUJP. Accuracy and model size are used as primary metrics for ranking the performance of the models. We deploy the most suitable model in an application system. The application system is constrained to a user-script on the client-side and a web service running on a cloud server. We utilize Tampermonkey (a cross-browser extension manager) and Render (a platform as a service vendor with a free-forever tier) in deploying the application system to minimize cost of deployment.

\section{Significance of the Research}
\label{sec:significance}

Our study is significant to the field of machine learning and fake news detection due to the following reasons.

Building on the work of \citeA{cruz2020localization}, our study contributes to the field of machine learning and computer science by investigating possible machine learning models that can distinguish between fake and authentic Filipino language news articles. We offer a more extensive and diverse collection of news articles by building a dataset similar to Fake News Filipino \cite{fake-news-filipino}. Our approach not only enhances the robustness of potential models in this study, but also provides a more comprehensive dataset that may be utilized in future research.

Furthermore, we provide a lightweight application system for the Filipino audience to aid them in fact-checking and avoiding harm caused by fake news. We pave the way for the low-cost deployment of fake news classifiers to the benefit of various institutions, particularly those engaged in tagging websites that publish fake news. The exploration of low-cost machine learning deployment strategies is beneficial for computer scientists aiming to implement machine learning models in resource-constrained contexts. Our results could further the development of cost-effective solutions when deploying machine learning models in various settings.

For policymakers, our study provides them with leverage in informing and shaping policies congruent to information integrity. The low-cost deployment of effective fake news detection classifiers may be integrated into broader strategies aimed at preventing the spread of misinformation and maintaining a trustworthy Filipino news network. The deployment of a lightweight application system for fake news detection may serve as a practical tool for policymakers to empower the public in distinguishing between fake and authentic news. We dedicate our efforts in this study to promoting media literacy and arming individuals with an accessible fact-checking tool to combat fake news effectively.
